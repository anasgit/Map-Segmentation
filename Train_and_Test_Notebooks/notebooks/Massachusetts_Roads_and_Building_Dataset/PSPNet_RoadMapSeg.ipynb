{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSPNet_RoadMapSeg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EttPfqDEymfq",
        "colab_type": "text"
      },
      "source": [
        "#Semantic Segmentation of Aerial Images\n",
        "###Road Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGkz_jLSz3_k",
        "colab_type": "text"
      },
      "source": [
        "####Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp1XESIw_CJP",
        "colab_type": "code",
        "outputId": "44843f83-54d0-4585-c52b-a840b3c3a252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "base_path = \"gdrive/My\\ Drive/MapSegClean/\"\n",
        "%cd gdrive/My\\ Drive/MapSegClean/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n",
            "/content/gdrive/My Drive/MapSegClean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmuIKqGIy03M",
        "colab_type": "text"
      },
      "source": [
        "####Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLs7ouvD_Ox8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Wjplyd_O8g",
        "colab_type": "code",
        "outputId": "3719713c-d2c8-4856-aafb-de6e837d6328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aFHDPl3_PAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, load_model\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras import optimizers\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "import keras\n",
        "\n",
        "from skimage import color\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YblNbuv_zCsz",
        "colab_type": "text"
      },
      "source": [
        "####Read Data From h5 files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XHC2-Eb_PDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h5f = h5py.File('Cpy_clean_roadlabel.h5','r')\n",
        "roadlabel = h5f['clean_roadlabel'][:]\n",
        "h5f.close()\n",
        "\n",
        "h5f = h5py.File('Cpy_clean_road.h5','r')\n",
        "road = h5f['clean_road'][:]\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tX5CGhQJyRMW",
        "outputId": "ebbdb35a-b861-4543-c2cf-b961fc102e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "#for i in range(road.shape[0]):\n",
        "#  cv2.imwrite(\"Road/\" + str(i) + \".png\", road[i])\n",
        "\n",
        "#for i in range(roadlabel.shape[0]):\n",
        "#  cv2.imwrite(\"RoadLabel/\" + str(i) + \".png\", roadlabel[i])\n",
        "pip install -U segmentation-models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation-models\n",
            "  Downloading https://files.pythonhosted.org/packages/da/b9/4a183518c21689a56b834eaaa45cad242d9ec09a4360b5b10139f23c63f4/segmentation_models-1.0.1-py3-none-any.whl\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from segmentation-models) (1.0.8)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.1.3)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (6.2.2)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.6)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (45.2.0)\n",
            "Installing collected packages: image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_FvtUV8zLLO",
        "colab_type": "text"
      },
      "source": [
        "####Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCQmMVMM_PIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
        "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "  return iou\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth = 1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def soft_dice_loss(y_true, y_pred):\n",
        "    return 1-dice_coef(y_true, y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h60tIIAZzUFk",
        "colab_type": "text"
      },
      "source": [
        "####Preprocecssing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz9UxbKN_PKT",
        "colab_type": "code",
        "outputId": "6bdd52f4-8418-4572-fa29-5c0379f93a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(roadlabel.shape)\n",
        "\n",
        "roadlabelgray = []\n",
        "\n",
        "for i in range(roadlabel.shape[0]):\n",
        "  roadlabelgray.append(cv2.cvtColor(roadlabel[i], cv2.COLOR_BGR2GRAY))\n",
        "\n",
        "roadlabelgray = np.asarray(roadlabelgray)\n",
        "\n",
        "roadlabel = np.expand_dims(roadlabelgray, -1)\n",
        "\n",
        "del roadlabelgray\n",
        "\n",
        "print(roadlabel.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22911, 256, 256, 3)\n",
            "(22911, 256, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qviu35nTgVf7",
        "colab_type": "code",
        "outputId": "2b0e1e2c-706d-424a-dd3e-452f7e082ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(roadlabel[:, 8:256-8, 8:256-8].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22911, 240, 240, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyK64qk8_3xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 56\n",
        "IMAGE_HEIGHT = IMAGE_WIDTH = 256\n",
        "NUM_CHANNELS = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifTwsREszadP",
        "colab_type": "text"
      },
      "source": [
        "####Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezvkK5_K06kv",
        "colab_type": "code",
        "outputId": "cf2f86de-648c-4778-894a-f245432c29a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from segmentation_models import PSPNet\n",
        "from segmentation_models import get_preprocessing\n",
        "from segmentation_models.losses import bce_jaccard_loss\n",
        "from segmentation_models.metrics import iou_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvDhuoGCyLfa",
        "colab_type": "code",
        "outputId": "df2fb33e-bddd-4356-8d5e-a2be8ede9177",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = PSPNet(input_shape=(240, 240, 3), encoder_weights=None, classes=1, psp_use_batchnorm=True, psp_pooling_type='max', activation='sigmoid')\n",
        "#model = Unet(input_shape=(256, 256, 3), weights=None, activation='elu')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2241: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 240, 240, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 240, 240, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 240, 240, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 120, 120, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 120, 120, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 120, 120, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 60, 60, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 60, 60, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 60, 60, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 60, 60, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 30, 30, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 30, 30, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 30, 30, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 30, 30, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "psp_level1_pooling (MaxPooling2 (None, 1, 1, 512)    0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "psp_level2_pooling (MaxPooling2 (None, 2, 2, 512)    0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "psp_level3_pooling (MaxPooling2 (None, 3, 3, 512)    0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "psp_level6_pooling (MaxPooling2 (None, 6, 6, 512)    0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "psp_level1_conv (Conv2D)        (None, 1, 1, 512)    262144      psp_level1_pooling[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "psp_level2_conv (Conv2D)        (None, 2, 2, 512)    262144      psp_level2_pooling[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "psp_level3_conv (Conv2D)        (None, 3, 3, 512)    262144      psp_level3_pooling[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "psp_level6_conv (Conv2D)        (None, 6, 6, 512)    262144      psp_level6_pooling[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "psp_level1_bn (BatchNormalizati (None, 1, 1, 512)    2048        psp_level1_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "psp_level2_bn (BatchNormalizati (None, 2, 2, 512)    2048        psp_level2_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "psp_level3_bn (BatchNormalizati (None, 3, 3, 512)    2048        psp_level3_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "psp_level6_bn (BatchNormalizati (None, 6, 6, 512)    2048        psp_level6_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "psp_level1_relu (Activation)    (None, 1, 1, 512)    0           psp_level1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "psp_level2_relu (Activation)    (None, 2, 2, 512)    0           psp_level2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "psp_level3_relu (Activation)    (None, 3, 3, 512)    0           psp_level3_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "psp_level6_relu (Activation)    (None, 6, 6, 512)    0           psp_level6_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "psp_level1_upsampling (UpSampli (None, 30, 30, 512)  0           psp_level1_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "psp_level2_upsampling (UpSampli (None, 30, 30, 512)  0           psp_level2_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "psp_level3_upsampling (UpSampli (None, 30, 30, 512)  0           psp_level3_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "psp_level6_upsampling (UpSampli (None, 30, 30, 512)  0           psp_level6_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "psp_concat (Concatenate)        (None, 30, 30, 2560) 0           block4_conv3[0][0]               \n",
            "                                                                 psp_level1_upsampling[0][0]      \n",
            "                                                                 psp_level2_upsampling[0][0]      \n",
            "                                                                 psp_level3_upsampling[0][0]      \n",
            "                                                                 psp_level6_upsampling[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "aggregation_conv (Conv2D)       (None, 30, 30, 512)  1310720     psp_concat[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "aggregation_bn (BatchNormalizat (None, 30, 30, 512)  2048        aggregation_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "aggregation_relu (Activation)   (None, 30, 30, 512)  0           aggregation_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "final_conv (Conv2D)             (None, 30, 30, 1)    4609        aggregation_relu[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "final_upsampling (UpSampling2D) (None, 240, 240, 1)  0           final_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "sigmoid (Activation)            (None, 240, 240, 1)  0           final_upsampling[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 10,009,409\n",
            "Trainable params: 10,004,289\n",
            "Non-trainable params: 5,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INigDuT8zjRt",
        "colab_type": "text"
      },
      "source": [
        "####Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXT5cJEy_PMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1bbgBHNzxPs",
        "colab_type": "text"
      },
      "source": [
        "####Path to save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4vsmUTqAAh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = \"Models/Final_PSPNet_road_weights.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO9Sz4uMs_k2",
        "colab_type": "code",
        "outputId": "5e4c265a-e64f-4652-ba62-52d55a868992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "import sys\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
        "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
        "        num /= 1024.0\n",
        "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
        "\n",
        "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
        "                         key= lambda x: -x[1])[:10]:\n",
        "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          road:  4.2 GiB\n",
            "                         Model:  2.0 KiB\n",
            "                        Conv2D:  2.0 KiB\n",
            "            BatchNormalization:  2.0 KiB\n",
            "                  MaxPooling2D:  1.4 KiB\n",
            "                       Dropout:  1.0 KiB\n",
            "                        Lambda:  1.0 KiB\n",
            "               Conv2DTranspose:  1.0 KiB\n",
            "                       MeanIoU:  1.0 KiB\n",
            "                           _i7:  615.0 B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AfXWpvIy1wD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sPbOLWJzo99",
        "colab_type": "text"
      },
      "source": [
        "####Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKH7fxFPAAfW",
        "colab_type": "code",
        "outputId": "455a4078-d40c-49f2-e0ed-58b7593aa1cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://f19c2793.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTbz0llbAAkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from datetime import datetime\n",
        "\n",
        "checkpointer = ModelCheckpoint(model_path,\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMdYZwNvAAmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlystopper = EarlyStopping(monitor = 'val_loss', \n",
        "                             min_delta = 0, \n",
        "                             patience = 7,\n",
        "                             mode='auto',\n",
        "                            restore_best_weights = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4bKCiiPAVvX",
        "colab_type": "code",
        "outputId": "e29742d1-afa1-4451-841a-e470ec6e6a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss',\n",
        "                               factor=0.1,\n",
        "                               patience=4,\n",
        "                               verbose=1,\n",
        "                               epsilon=1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn9dywIv0CGD",
        "colab_type": "text"
      },
      "source": [
        "####Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrgM5RWvAVzq",
        "colab_type": "code",
        "outputId": "a40ae39f-87c6-4d40-90d6-ca0905a7648a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "opt = keras.optimizers.adam(LEARNING_RATE)\n",
        "model.compile(\n",
        "      optimizer=opt,\n",
        "      loss=soft_dice_loss,\n",
        "      metrics=[iou_coef])   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRxH6o6AAV95",
        "colab_type": "code",
        "outputId": "f176bcca-cecd-4f5f-bc0b-4bfbb0771c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        }
      },
      "source": [
        "history = model.fit(road[:, 8:256-8, 8:256-8],\n",
        "                    (roadlabel[:, 8:256-8, 8:256-8].astype(np.uint8)/255).astype(np.uint8),\n",
        "                    validation_split = 0.1,\n",
        "                    epochs=100,\n",
        "                    batch_size = 32,\n",
        "                    callbacks = [checkpointer, earlystopper, lr_reducer, TensorBoardColabCallback(tbc)]\n",
        "                       )\n",
        "\n",
        "with open(\"History/PSPNet_Road_History.pickle\", 'wb') as f:\n",
        "    pickle.dump(history, f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20619 samples, validate on 2292 samples\n",
            "Epoch 1/100\n",
            "20619/20619 [==============================] - 824s 40ms/step - loss: 0.4195 - iou_coef: 0.3520 - val_loss: 0.4169 - val_iou_coef: 0.4025\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.41689, saving model to Models/Final_PSPNet_road_weights.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/callbacks.py:51: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/100\n",
            "20619/20619 [==============================] - 809s 39ms/step - loss: 0.3289 - iou_coef: 0.4790 - val_loss: 0.3187 - val_iou_coef: 0.4842\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.41689 to 0.31869, saving model to Models/Final_PSPNet_road_weights.h5\n",
            "Epoch 3/100\n",
            "20619/20619 [==============================] - 809s 39ms/step - loss: 0.3080 - iou_coef: 0.5242 - val_loss: 0.3073 - val_iou_coef: 0.5421\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.31869 to 0.30732, saving model to Models/Final_PSPNet_road_weights.h5\n",
            "Epoch 4/100\n",
            "20619/20619 [==============================] - 810s 39ms/step - loss: 0.2944 - iou_coef: 0.5451 - val_loss: 0.3071 - val_iou_coef: 0.5212\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.30732 to 0.30714, saving model to Models/Final_PSPNet_road_weights.h5\n",
            "Epoch 5/100\n",
            "20619/20619 [==============================] - 811s 39ms/step - loss: 0.2850 - iou_coef: 0.5664 - val_loss: 0.2886 - val_iou_coef: 0.5473\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.30714 to 0.28864, saving model to Models/Final_PSPNet_road_weights.h5\n",
            "Epoch 6/100\n",
            "20619/20619 [==============================] - 809s 39ms/step - loss: 0.2762 - iou_coef: 0.5792 - val_loss: 0.2814 - val_iou_coef: 0.5637\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.28864 to 0.28137, saving model to Models/Final_PSPNet_road_weights.h5\n",
            "Epoch 7/100\n",
            "20619/20619 [==============================] - 808s 39ms/step - loss: 0.2690 - iou_coef: 0.5924 - val_loss: 0.2818 - val_iou_coef: 0.5782\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.28137\n",
            "Epoch 8/100\n",
            "20619/20619 [==============================] - 809s 39ms/step - loss: 0.2622 - iou_coef: 0.6017 - val_loss: 0.2760 - val_iou_coef: 0.5892\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.28137 to 0.27600, saving model to Models/Final_PSPNet_road_weights.h5\n",
            "Epoch 9/100\n",
            "20619/20619 [==============================] - 809s 39ms/step - loss: 0.2563 - iou_coef: 0.6104 - val_loss: 0.2730 - val_iou_coef: 0.5828\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.27600 to 0.27303, saving model to Models/Final_PSPNet_road_weights.h5\n",
            "Epoch 10/100\n",
            "20619/20619 [==============================] - 807s 39ms/step - loss: 0.2503 - iou_coef: 0.6213 - val_loss: 0.2762 - val_iou_coef: 0.5960\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.27303\n",
            "Epoch 11/100\n",
            "20619/20619 [==============================] - 808s 39ms/step - loss: 0.2438 - iou_coef: 0.6321 - val_loss: 0.2761 - val_iou_coef: 0.6023\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.27303\n",
            "Epoch 12/100\n",
            "10976/20619 [==============>...............] - ETA: 6:05 - loss: 0.2387 - iou_coef: 0.6395"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgcZk2DVNOxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pickle\n",
        "#with open(\"History/Road_History.pickle\", 'rb') as f:\n",
        "#    history = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0SYiVaDAP7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['iou_coef'])\n",
        "plt.plot(history.history['val_iou_coef'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GmXHogIamoz",
        "colab_type": "code",
        "outputId": "c2017618-15b9-427c-e962-1a42eedd43df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.load_weights(model_path)\n",
        "\n",
        "history = model.fit(road[:, 8:256-8, 8:256-8],\n",
        "                    (roadlabel[:, 8:256-8, 8:256-8].astype(np.uint8)/255).astype(np.uint8),\n",
        "                    validation_split = 0.1,\n",
        "                    epochs=100,\n",
        "                    batch_size = 32,\n",
        "                    callbacks = [checkpointer, earlystopper, lr_reducer, TensorBoardColabCallback(tbc)]\n",
        "                       )\n",
        "\n",
        "with open(\"History/PSPNet_Road_History_1.pickle\", 'wb') as f:\n",
        "    pickle.dump(history, f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 20619 samples, validate on 2292 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "Epoch 1/100\n",
            "20619/20619 [==============================] - 221s 11ms/step - loss: 0.2304 - iou_coef: 0.6512 - val_loss: 0.2681 - val_iou_coef: 0.6050\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.26814, saving model to Models/Final_PSPNet_road_weights.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/callbacks.py:51: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.2252 - iou_coef: 0.6608 - val_loss: 0.3049 - val_iou_coef: 0.5751\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.26814\n",
            "Epoch 3/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.2208 - iou_coef: 0.6639 - val_loss: 0.2723 - val_iou_coef: 0.6049\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.26814\n",
            "Epoch 4/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.2171 - iou_coef: 0.6745 - val_loss: 0.2632 - val_iou_coef: 0.6104\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.26814 to 0.26317, saving model to Models/Final_PSPNet_road_weights.h5\n",
            "Epoch 5/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.2134 - iou_coef: 0.6779 - val_loss: 0.2739 - val_iou_coef: 0.5797\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.26317\n",
            "Epoch 6/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.2081 - iou_coef: 0.6843 - val_loss: 0.2651 - val_iou_coef: 0.6087\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.26317\n",
            "Epoch 7/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.2043 - iou_coef: 0.6916 - val_loss: 0.2648 - val_iou_coef: 0.6121\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.26317\n",
            "Epoch 8/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.2009 - iou_coef: 0.6944 - val_loss: 0.2645 - val_iou_coef: 0.6077\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.26317\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 9/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.1899 - iou_coef: 0.7145 - val_loss: 0.2589 - val_iou_coef: 0.6172\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.26317 to 0.25890, saving model to Models/Final_PSPNet_road_weights.h5\n",
            "Epoch 10/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.1855 - iou_coef: 0.7208 - val_loss: 0.2595 - val_iou_coef: 0.6157\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.25890\n",
            "Epoch 11/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.1834 - iou_coef: 0.7247 - val_loss: 0.2593 - val_iou_coef: 0.6162\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.25890\n",
            "Epoch 12/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.1816 - iou_coef: 0.7250 - val_loss: 0.2606 - val_iou_coef: 0.6102\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.25890\n",
            "Epoch 13/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.1797 - iou_coef: 0.7279 - val_loss: 0.2615 - val_iou_coef: 0.6141\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.25890\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 14/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.1775 - iou_coef: 0.7331 - val_loss: 0.2611 - val_iou_coef: 0.6124\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.25890\n",
            "Epoch 15/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.1771 - iou_coef: 0.7335 - val_loss: 0.2611 - val_iou_coef: 0.6123\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.25890\n",
            "Epoch 16/100\n",
            "20619/20619 [==============================] - 210s 10ms/step - loss: 0.1771 - iou_coef: 0.7332 - val_loss: 0.2612 - val_iou_coef: 0.6119\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.25890\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}