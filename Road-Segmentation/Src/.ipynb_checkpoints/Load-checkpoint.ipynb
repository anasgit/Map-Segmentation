{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3WSjIHnbEG3"
   },
   "source": [
    "# Segmentation of Road from Satellite imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p1ZeiWO9bSrT"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUHhxUFxxOaU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "#from google.colab.patches import cv2_imshow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.models import Model, load_model\n",
    "from skimage.morphology import label\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import random\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "\n",
    "seed = 56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aS3yy-MoxNJd"
   },
   "source": [
    "## Defining Custom Loss functions and accuracy Metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmI15mzGmD_R"
   },
   "outputs": [],
   "source": [
    "#Source: https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2\n",
    "from keras import backend as K\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "  \n",
    "  return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxUwv6N4gwQ0"
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def soft_dice_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icu1-GbRxkor"
   },
   "source": [
    "## Defining Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RAw-OnW57dm9"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import optimizers\n",
    "from keras.layers import BatchNormalization\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jRN88N68SB2k",
    "outputId": "543f26e6-e7f6-4ece-c1d8-dde4d9e0b19a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256, 256, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 16) 2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 32) 9248        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 32) 128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 128)  147584      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 256)  590080      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 128)  131200      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 128)  147584      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 64)   32832       batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 64)   36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 32) 8224        batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 32) 128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128, 128, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 32) 9248        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 16) 2064        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 256, 16) 64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 256, 256, 16) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 16) 2320        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256, 256, 16) 64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 1)  17          batch_normalization_18[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,946,993\n",
      "Trainable params: 1,944,049\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((256, 256, 3))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "conv1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
    "conv1 = BatchNormalization() (conv1)\n",
    "conv1 = Dropout(0.1) (conv1)\n",
    "conv1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1)\n",
    "conv1 = BatchNormalization() (conv1)\n",
    "pooling1 = MaxPooling2D((2, 2)) (conv1)\n",
    "\n",
    "conv2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling1)\n",
    "conv2 = BatchNormalization() (conv2)\n",
    "conv2 = Dropout(0.1) (conv2)\n",
    "conv2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2)\n",
    "conv2 = BatchNormalization() (conv2)\n",
    "pooling2 = MaxPooling2D((2, 2)) (conv2)\n",
    "\n",
    "conv3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling2)\n",
    "conv3 = BatchNormalization() (conv3)\n",
    "conv3 = Dropout(0.2) (conv3)\n",
    "conv3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3)\n",
    "conv3 = BatchNormalization() (conv3)\n",
    "pooling3 = MaxPooling2D((2, 2)) (conv3)\n",
    "\n",
    "conv4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling3)\n",
    "conv4 = BatchNormalization() (conv4)\n",
    "conv4 = Dropout(0.2) (conv4)\n",
    "conv4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4)\n",
    "conv4 = BatchNormalization() (conv4)\n",
    "pooling4 = MaxPooling2D(pool_size=(2, 2)) (conv4)\n",
    "\n",
    "conv5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling4)\n",
    "conv5 = BatchNormalization() (conv5)\n",
    "conv5 = Dropout(0.3) (conv5)\n",
    "conv5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv5)\n",
    "conv5 = BatchNormalization() (conv5)\n",
    "\n",
    "\n",
    "upsample6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (conv5)\n",
    "upsample6 = concatenate([upsample6, conv4])\n",
    "conv6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample6)\n",
    "conv6 = BatchNormalization() (conv6)\n",
    "conv6 = Dropout(0.2) (conv6)\n",
    "conv6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv6)\n",
    "conv6 = BatchNormalization() (conv6)\n",
    "\n",
    "upsample7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (conv6)\n",
    "upsample7 = concatenate([upsample7, conv3])\n",
    "conv7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample7)\n",
    "conv7 = BatchNormalization() (conv7)\n",
    "conv7 = Dropout(0.2) (conv7)\n",
    "conv7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv7)\n",
    "conv7 = BatchNormalization() (conv7)\n",
    "\n",
    "upsample8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (conv7)\n",
    "upsample8 = concatenate([upsample8, conv2])\n",
    "conv8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample8)\n",
    "conv8 = BatchNormalization() (conv8)\n",
    "conv8 = Dropout(0.1) (conv8)\n",
    "conv8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv8)\n",
    "conv8 = BatchNormalization() (conv8)\n",
    "\n",
    "upsample9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (conv8)\n",
    "upsample9 = concatenate([upsample9, conv1], axis=3)\n",
    "conv9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample9)\n",
    "conv9 = BatchNormalization() (conv9)\n",
    "conv9 = Dropout(0.1) (conv9)\n",
    "conv9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv9)\n",
    "conv9 = BatchNormalization() (conv9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrmWnkYJB8uj"
   },
   "source": [
    "### HYPER_PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbnY2mIDDVZN"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvDS_wY7D9sq"
   },
   "source": [
    "### Initializing Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Au-ZS3kKEs5V"
   },
   "outputs": [],
   "source": [
    "#from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3e-jHbcDTxb"
   },
   "outputs": [],
   "source": [
    "model_path = \"./Models/road_mapper_2.h5\"\n",
    "checkpointer = ModelCheckpoint(model_path,\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 5,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=4,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6sX2f-L_UrQ"
   },
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSW1jCBF-_R5"
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.adam(LEARNING_RATE)\n",
    "model.compile(\n",
    "      optimizer=opt,\n",
    "      loss=soft_dice_loss,\n",
    "      metrics=[iou_coef])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19gHX8-TBVJp"
   },
   "source": [
    "## Testing our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "150dL9XqskGW"
   },
   "source": [
    "### On Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHcafCucPwsN"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"/home/parshwa/Desktop/Road-Segmentation/Models/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Visualise\"\"\"\n",
    "def layer_to_visualize(layer):\n",
    "    inputs = [K.learning_phase()] + model.inputs\n",
    "\n",
    "    _convout1_f = K.function(inputs, [layer.output])\n",
    "    def convout1_f(X):\n",
    "        # The [0] is to disable the training phase flag\n",
    "        return _convout1_f([0] + [X])\n",
    "\n",
    "    convolutions = convout1_f(img_to_visualize)\n",
    "    convolutions = np.squeeze(convolutions)\n",
    "\n",
    "    print ('Shape of conv:', convolutions.shape)\n",
    "\n",
    "    n = convolutions.shape[0]\n",
    "    n = int(np.ceil(np.sqrt(n)))\n",
    "\n",
    "    # Visualization of each filter of the layer\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    for i in range(len(convolutions)):\n",
    "        ax = fig.add_subplot(n,n,i+1)\n",
    "        ax.imshow(convolutions[i], cmap='gray')\n",
    "print(type(conv1))\n",
    "#layer_to_visualize(conv1)\n",
    "\n",
    "#print(type(model.get_layer(conv1)))\n",
    "#print(model.get_layer(conv1).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10378690_15_24.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10378675_15_14.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228660_15_20.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228705_15_22.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10378675_15_4.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10078735_15_25.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10378690_15_4.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228675_15_22.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10078690_15_18.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10078690_15_16.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228735_15_20.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228705_15_24.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10078660_15_4.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10378690_15_5.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10378675_15_24.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10378675_15_13.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228720_15_2.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10378660_15_19.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228735_15_13.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10078720_15_14.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228705_15_7.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228765_15_25.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228675_15_6.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228675_15_14.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10078720_15_18.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228750_15_12.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228720_15_16.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228750_15_5.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228675_15_9.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestI/10228705_15_19.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10378690_15_24.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10378675_15_14.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228660_15_20.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228705_15_22.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10378675_15_4.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10078735_15_25.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10378690_15_4.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228675_15_22.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10078690_15_18.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10078690_15_16.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228735_15_20.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228705_15_24.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10078660_15_4.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10378690_15_5.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10378675_15_24.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10378675_15_13.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228720_15_2.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10378660_15_19.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228735_15_13.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10078720_15_14.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228705_15_7.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228765_15_25.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228675_15_6.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228675_15_14.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10078720_15_18.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228750_15_12.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228720_15_16.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228750_15_5.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228675_15_9.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/TestM/10228705_15_19.png\n",
      "Unique elements in the train mask: [  0 255]\n",
      "(30, 256, 256, 3)\n",
      "(30, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "#test_images = np.array([cv2.imread(file) for file in glob.glob(\"/home/bisag/Desktop/Road-Segmentation/I/\")])\n",
    "#test_masks = np.array([cv2.imread(file) for file in glob.glob(\"/home/bisag/Desktop/Road-Segmentation/M/\")])\n",
    "\n",
    "test_images = []\n",
    "files = glob.glob (\"/home/parshwa/Desktop/Road-Segmentation/TestI/*.png\")\n",
    "for myFile in files:\n",
    "    print(myFile)\n",
    "    image = cv2.imread (myFile)\n",
    "    test_images.append (image)\n",
    "\n",
    "test_masks = []\n",
    "files = glob.glob (\"/home/parshwa/Desktop/Road-Segmentation/TestM/*.png\")\n",
    "for myFile in files:\n",
    "    print(myFile)\n",
    "    image = cv2.cvtColor(cv2.imread (myFile), cv2.COLOR_BGR2GRAY)\n",
    "    test_masks.append (image)\n",
    "\n",
    "    \n",
    "#test_images = cv2.imread(\"/home/bisag/Desktop/Road-Segmentation/I/1.png\")\n",
    "#test_masks = cv2.imread(\"/home/bisag/Desktop/Road-Segmentation/M/1.png\")\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_masks = np.array(test_masks)\n",
    "\n",
    "test_masks = np.expand_dims(test_masks, -1)\n",
    "print(\"Unique elements in the train mask:\", np.unique(test_masks))\n",
    "\n",
    "print(test_images.shape)\n",
    "print(test_masks.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylpqQZ6dejCZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "30/30 [==============================] - 100s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.7337696552276611, 11.635106086730957]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7TbTMDUqPy0l",
    "outputId": "c9db82e0-8def-44bd-b8b8-cf30cb2e4f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "30/30 [==============================] - 26s 876ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aRCjSMKBXJ1"
   },
   "outputs": [],
   "source": [
    "thresh_val = 0.1\n",
    "predicton_threshold = (predictions > thresh_val).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    cv2.imwrite( \"/home/parshwa/Desktop/Road-Segmentation/Results/\" + str(i) + \"Image.png\"  , np.squeeze(test_images[i][:,:,0]))\n",
    "    cv2.imwrite( \"/home/parshwa/Desktop/Road-Segmentation/Results/\" + str(i) + \"GroundTruth.png\"  , np.squeeze(test_masks[i][:,:,0]))\n",
    "    #cv2.imwrite( \"/home/bisag/Desktop/Road-Segmentation/Results/\" + str(i) + \"Prediction.png\"  , np.squeeze(predictions[i][:,:,0]))\n",
    "    #cv2.imwrite( \"/home/bisag/Desktop/Road-Segmentation/Results/\" + str(i) + \"Prediction_Threshold.png\"  , np.squeeze(predicton_threshold[i][:,:,0]))\n",
    "    #matplotlib.image.imsave('/home/bisag/Desktop/Road-Segmentation/Results/000.png', np.squeeze(predicton_threshold[0][:,:,0]))\n",
    "    matplotlib.image.imsave(\"/home/parshwa/Desktop/Road-Segmentation/Results/\" + str(i) + \"Prediction.png\"  , np.squeeze(predictions[i][:,:,0]))\n",
    "    matplotlib.image.imsave( \"/home/parshwa/Desktop/Road-Segmentation/Results/\" + str(i) + \"Prediction_Threshold.png\"  , np.squeeze(predicton_threshold[i][:,:,0]))\n",
    "\n",
    "    #imshow(np.squeeze(predictions[0][:,:,0]))\n",
    "\n",
    "imshow(np.squeeze(predictions[0][:,:,0]))\n",
    "\n",
    "#import scipy.misc\n",
    "#scipy.misc.imsave('/home/bisag/Desktop/Road-Segmentation/Results/00.png', np.squeeze(predictions[0][:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"/home/parshwa/Desktop/Road-Segmentation/Models/weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_4.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_11.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_3.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_2.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_15.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_12.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_14.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_9.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_8.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_1.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_5.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_16.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_13.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_10.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_7.png\n",
      "/home/parshwa/Desktop/Road-Segmentation/Test/RImage1_6.png\n",
      "(16, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test\"\"\"\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "#test_images = np.array([cv2.imread(file) for file in glob.glob(\"/home/bisag/Desktop/Road-Segmentation/I/\")])\n",
    "#test_masks = np.array([cv2.imread(file) for file in glob.glob(\"/home/bisag/Desktop/Road-Segmentation/M/\")])\n",
    "\n",
    "test_images = []\n",
    "files = glob.glob (\"/home/parshwa/Desktop/Road-Segmentation/Test/*.png\")\n",
    "for myFile in files:\n",
    "    print(myFile)\n",
    "    image = cv2.imread (myFile)\n",
    "    test_images.append (image)\n",
    "\n",
    "\n",
    "    \n",
    "#test_images = cv2.imread(\"/home/bisag/Desktop/Road-Segmentation/I/1.png\")\n",
    "#test_masks = cv2.imread(\"/home/bisag/Desktop/Road-Segmentation/M/1.png\")\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "print(test_images.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "16/16 [==============================] - 11s 718ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_val = 0.1\n",
    "predicton_threshold = (predictions > thresh_val).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicton_threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b16e398473a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#matplotlib.image.imsave('/home/bisag/Desktop/Road-Segmentation/Results/000.png', np.squeeze(predicton_threshold[0][:,:,0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/parshwa/Desktop/Road-Segmentation/Results/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Prediction.png\"\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"/home/parshwa/Desktop/Road-Segmentation/Results/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Prediction_Threshold.png\"\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicton_threshold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#imshow(np.squeeze(predictions[0][:,:,0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicton_threshold' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    cv2.imwrite( \"/home/parshwa/Desktop/Road-Segmentation/Results/\" + str(i) + \"Image.png\"  , np.squeeze(test_images[i][:,:,0]))\n",
    "    #cv2.imwrite( \"/home/bisag/Desktop/Road-Segmentation/Results/\" + str(i) + \"Prediction.png\"  , np.squeeze(predictions[i][:,:,0]))\n",
    "    #cv2.imwrite( \"/home/bisag/Desktop/Road-Segmentation/Results/\" + str(i) + \"Prediction_Threshold.png\"  , np.squeeze(predicton_threshold[i][:,:,0]))\n",
    "    #matplotlib.image.imsave('/home/bisag/Desktop/Road-Segmentation/Results/000.png', np.squeeze(predicton_threshold[0][:,:,0]))\n",
    "    matplotlib.image.imsave(\"/home/parshwa/Desktop/Road-Segmentation/Results/\" + str(i) + \"Prediction.png\"  , np.squeeze(predictions[i][:,:,0]))\n",
    "    matplotlib.image.imsave( \"/home/parshwa/Desktop/Road-Segmentation/Results/\" + str(i) + \"Prediction_Threshold.png\"  , np.squeeze(predicton_threshold[i][:,:,0]))\n",
    "\n",
    "    #imshow(np.squeeze(predictions[0][:,:,0]))\n",
    "\n",
    "imshow(np.squeeze(predictions[0][:,:,0]))\n",
    "\n",
    "#import scipy.misc\n",
    "#scipy.misc.imsave('/home/bisag/Desktop/Road-Segmentation/Results/00.png', np.squeeze(predictions[0][:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualise\"\"\"\n",
    "def layer_to_visualize(layer):\n",
    "    inputs = [K.learning_phase()] + model.inputs\n",
    "\n",
    "    _convout1_f = K.function(inputs, [layer.output])\n",
    "    def convout1_f(X):\n",
    "        # The [0] is to disable the training phase flag\n",
    "        return _convout1_f([0] + [X])\n",
    "\n",
    "    convolutions = convout1_f(img_to_visualize)\n",
    "    convolutions = np.squeeze(convolutions)\n",
    "\n",
    "    print ('Shape of conv:', convolutions.shape)\n",
    "\n",
    "    n = convolutions.shape[0]\n",
    "    n = int(np.ceil(np.sqrt(n)))\n",
    "\n",
    "    # Visualization of each filter of the layer\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    for i in range(len(convolutions)):\n",
    "        ax = fig.add_subplot(n,n,i+1)\n",
    "        ax.imshow(convolutions[i], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Road Detection - GPU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
