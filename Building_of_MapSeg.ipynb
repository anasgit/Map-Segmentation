{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building of MapSeg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPhEEFFY6KzYLOfw1I6FSWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parshwa1999/Map-Segmentation/blob/master/Building_of_MapSeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp1XESIw_CJP",
        "colab_type": "code",
        "outputId": "cbc8a006-f3b5-407e-c2bf-025c21013307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "base_path = \"gdrive/My\\ Drive/MapSegClean/\"\n",
        "%cd gdrive/My\\ Drive/MapSegClean/\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n",
            "/content/gdrive/My Drive/MapSegClean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLs7ouvD_Ox8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import h5py\n",
        "#import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Wjplyd_O8g",
        "colab_type": "code",
        "outputId": "47dc8c58-d592-496d-8607-cb053c83f02c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aFHDPl3_PAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, load_model\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras import optimizers\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "import keras\n",
        "\n",
        "from skimage import color"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XHC2-Eb_PDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h5f = h5py.File('BuildingLabels.h5','r')\n",
        "roadlabel = h5f['BuildingLabels'][:]\n",
        "h5f.close()\n",
        "\n",
        "h5f = h5py.File('BuildingImages.h5','r')\n",
        "road = h5f['BuildingImages'][:]\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTBdXGpS2ICe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in range(road.shape[0]):\n",
        "#  cv2.imwrite(\"Road/\" + str(i) + \".png\", road[i])\n",
        "\n",
        "#for i in range(roadlabel.shape[0]):\n",
        "#  cv2.imwrite(\"RoadLabel/\" + str(i) + \".png\", roadlabel[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCQmMVMM_PIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Loss Fuction\"\"\"\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
        "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "  return iou\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth = 1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def soft_dice_loss(y_true, y_pred):\n",
        "    return 1-dice_coef(y_true, y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz9UxbKN_PKT",
        "colab_type": "code",
        "outputId": "3e175cd7-b444-407e-8148-3a4e1c1e186f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(roadlabel.shape)\n",
        "\n",
        "roadlabelgray = []\n",
        "\n",
        "for i in range(roadlabel.shape[0]):\n",
        "  roadlabelgray.append(cv2.cvtColor(roadlabel[i], cv2.COLOR_BGR2GRAY))\n",
        "\n",
        "roadlabelgray = np.asarray(roadlabelgray)\n",
        "#del \n",
        "\n",
        "roadlabel = np.expand_dims(roadlabelgray, -1)\n",
        "print(roadlabel.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24520, 256, 256, 3)\n",
            "(24520, 256, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyK64qk8_3xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 56\n",
        "IMAGE_HEIGHT = IMAGE_WIDTH = 256\n",
        "NUM_CHANNELS = 3\n",
        "#del train_images, train_masks\n",
        "#del test_images, test_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpyukCaS_3_t",
        "colab_type": "code",
        "outputId": "ee79c244-8755-426c-a59f-3bfc3dd04aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"\n",
        "Model\n",
        "\"\"\"\n",
        "\n",
        "inputs = Input((IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "conv1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
        "conv1 = BatchNormalization() (conv1)\n",
        "conv1 = Dropout(0.1) (conv1)\n",
        "conv1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1)\n",
        "conv1 = BatchNormalization() (conv1)\n",
        "pooling1 = MaxPooling2D((2, 2)) (conv1)\n",
        "\n",
        "conv2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling1)\n",
        "conv2 = BatchNormalization() (conv2)\n",
        "conv2 = Dropout(0.1) (conv2)\n",
        "conv2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2)\n",
        "conv2 = BatchNormalization() (conv2)\n",
        "pooling2 = MaxPooling2D((2, 2)) (conv2)\n",
        "\n",
        "conv3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling2)\n",
        "conv3 = BatchNormalization() (conv3)\n",
        "conv3 = Dropout(0.2) (conv3)\n",
        "conv3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3)\n",
        "conv3 = BatchNormalization() (conv3)\n",
        "pooling3 = MaxPooling2D((2, 2)) (conv3)\n",
        "\n",
        "conv4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling3)\n",
        "conv4 = BatchNormalization() (conv4)\n",
        "conv4 = Dropout(0.2) (conv4)\n",
        "conv4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4)\n",
        "conv4 = BatchNormalization() (conv4)\n",
        "pooling4 = MaxPooling2D(pool_size=(2, 2)) (conv4)\n",
        "\n",
        "conv5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling4)\n",
        "conv5 = BatchNormalization() (conv5)\n",
        "conv5 = Dropout(0.3) (conv5)\n",
        "conv5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv5)\n",
        "conv5 = BatchNormalization() (conv5)\n",
        "\n",
        "\n",
        "upsample6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (conv5)\n",
        "upsample6 = concatenate([upsample6, conv4])\n",
        "conv6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample6)\n",
        "conv6 = BatchNormalization() (conv6)\n",
        "conv6 = Dropout(0.2) (conv6)\n",
        "conv6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv6)\n",
        "conv6 = BatchNormalization() (conv6)\n",
        "\n",
        "upsample7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (conv6)\n",
        "upsample7 = concatenate([upsample7, conv3])\n",
        "conv7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample7)\n",
        "conv7 = BatchNormalization() (conv7)\n",
        "conv7 = Dropout(0.2) (conv7)\n",
        "conv7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv7)\n",
        "conv7 = BatchNormalization() (conv7)\n",
        "\n",
        "upsample8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (conv7)\n",
        "upsample8 = concatenate([upsample8, conv2])\n",
        "conv8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample8)\n",
        "conv8 = BatchNormalization() (conv8)\n",
        "conv8 = Dropout(0.1) (conv8)\n",
        "conv8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv8)\n",
        "conv8 = BatchNormalization() (conv8)\n",
        "\n",
        "upsample9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (conv8)\n",
        "upsample9 = concatenate([upsample9, conv1], axis=3)\n",
        "conv9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample9)\n",
        "conv9 = BatchNormalization() (conv9)\n",
        "conv9 = Dropout(0.1) (conv9)\n",
        "conv9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv9)\n",
        "conv9 = BatchNormalization() (conv9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv9)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\n",
        "model.summary()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 256, 256, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 16) 2320        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 32) 9248        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128, 128, 32) 128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 64)   36928       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 128)  147584      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 256)  1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 16, 16, 256)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 256)  590080      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 128)  131200      batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 256)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 128)  147584      dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 64)   32832       batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_2[0][0]         \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 64, 64, 64)   36928       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 32) 8224        batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128, 128, 32) 128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 128, 128, 32) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 128, 128, 32) 9248        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128, 128, 32) 128         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 16) 2064        batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 256, 256, 16) 64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 256, 256, 16) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 256, 256, 16) 2320        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 256, 256, 16) 64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 256, 256, 1)  17          batch_normalization_18[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 1,946,993\n",
            "Trainable params: 1,944,049\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXT5cJEy_PMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Hyperparameters\n",
        "\"\"\"\n",
        "#print(roadlabel.shape)\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.0001\n",
        "BATCH_SIZE = 32\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKH7fxFPAAfW",
        "colab_type": "code",
        "outputId": "3987ff77-fd3c-431d-9bb4-04453caae4ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://fb062fa8.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4vsmUTqAAh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = \"Models/Final_unet_building_weights.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTbz0llbAAkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from datetime import datetime\n",
        "\n",
        "checkpointer = ModelCheckpoint(model_path,\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMdYZwNvAAmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlystopper = EarlyStopping(monitor = 'val_loss', \n",
        "                             min_delta = 0, \n",
        "                             patience = 7,\n",
        "                             mode='auto',\n",
        "                            restore_best_weights = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4bKCiiPAVvX",
        "colab_type": "code",
        "outputId": "ddc66297-d259-4af5-c884-7c5d790fde1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss',\n",
        "                               factor=0.1,\n",
        "                               patience=4,\n",
        "                               verbose=1,\n",
        "                               epsilon=1e-4)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrgM5RWvAVzq",
        "colab_type": "code",
        "outputId": "d1767f9f-468e-47f3-bf40-d342c428d7b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "opt = keras.optimizers.adam(LEARNING_RATE)\n",
        "model.compile(\n",
        "      optimizer=opt,\n",
        "      loss=soft_dice_loss,\n",
        "      metrics=[iou_coef])   "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlPu-0sYcG2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1911a107-2165-438d-8cbb-515d6172d103"
      },
      "source": [
        "history = model.fit(road,\n",
        "                    roadlabel.astype(np.float16)/255,\n",
        "                    validation_split = 0.1,\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size = BATCH_SIZE,\n",
        "                    callbacks = [checkpointer, earlystopper, lr_reducer, TensorBoardColabCallback(tbc)]\n",
        "                       )\n",
        "\n",
        "with open(\"History/Building_History.pickle\", 'wb') as f:\n",
        "    pickle.dump(history, f)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 22068 samples, validate on 2452 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "Epoch 1/100\n",
            "22068/22068 [==============================] - 183s 8ms/step - loss: 0.5140 - iou_coef: 0.2668 - val_loss: 0.4257 - val_iou_coef: 0.3286\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.42571, saving model to Models/Final_unet_building_weights.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/callbacks.py:51: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.3680 - iou_coef: 0.3780 - val_loss: 0.3328 - val_iou_coef: 0.4095\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.42571 to 0.33276, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 3/100\n",
            "22068/22068 [==============================] - 173s 8ms/step - loss: 0.3120 - iou_coef: 0.4312 - val_loss: 0.3028 - val_iou_coef: 0.4345\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.33276 to 0.30281, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 4/100\n",
            "22068/22068 [==============================] - 173s 8ms/step - loss: 0.2848 - iou_coef: 0.4606 - val_loss: 0.2796 - val_iou_coef: 0.4611\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.30281 to 0.27964, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 5/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2688 - iou_coef: 0.4792 - val_loss: 0.2680 - val_iou_coef: 0.4737\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.27964 to 0.26804, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 6/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2584 - iou_coef: 0.4926 - val_loss: 0.2647 - val_iou_coef: 0.4792\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.26804 to 0.26469, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 7/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2503 - iou_coef: 0.5030 - val_loss: 0.2554 - val_iou_coef: 0.4936\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.26469 to 0.25537, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 8/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2439 - iou_coef: 0.5121 - val_loss: 0.2564 - val_iou_coef: 0.4904\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.25537\n",
            "Epoch 9/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2391 - iou_coef: 0.5198 - val_loss: 0.2521 - val_iou_coef: 0.4994\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.25537 to 0.25207, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 10/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2342 - iou_coef: 0.5272 - val_loss: 0.2401 - val_iou_coef: 0.5221\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.25207 to 0.24010, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 11/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2309 - iou_coef: 0.5338 - val_loss: 0.2407 - val_iou_coef: 0.5188\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.24010\n",
            "Epoch 12/100\n",
            "22068/22068 [==============================] - 173s 8ms/step - loss: 0.2280 - iou_coef: 0.5410 - val_loss: 0.2317 - val_iou_coef: 0.5402\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.24010 to 0.23169, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 13/100\n",
            "22068/22068 [==============================] - 173s 8ms/step - loss: 0.2248 - iou_coef: 0.5494 - val_loss: 0.2400 - val_iou_coef: 0.5365\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.23169\n",
            "Epoch 14/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2218 - iou_coef: 0.5574 - val_loss: 0.2274 - val_iou_coef: 0.5607\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.23169 to 0.22744, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 15/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2198 - iou_coef: 0.5663 - val_loss: 0.2282 - val_iou_coef: 0.5675\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.22744\n",
            "Epoch 16/100\n",
            "22068/22068 [==============================] - 173s 8ms/step - loss: 0.2170 - iou_coef: 0.5767 - val_loss: 0.2250 - val_iou_coef: 0.5825\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.22744 to 0.22501, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 17/100\n",
            "22068/22068 [==============================] - 173s 8ms/step - loss: 0.2149 - iou_coef: 0.5849 - val_loss: 0.2256 - val_iou_coef: 0.5862\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.22501\n",
            "Epoch 18/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2126 - iou_coef: 0.5941 - val_loss: 0.2220 - val_iou_coef: 0.6004\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.22501 to 0.22201, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 19/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2109 - iou_coef: 0.6007 - val_loss: 0.2188 - val_iou_coef: 0.6133\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.22201 to 0.21882, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 20/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2087 - iou_coef: 0.6076 - val_loss: 0.2153 - val_iou_coef: 0.6192\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.21882 to 0.21526, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 21/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2076 - iou_coef: 0.6151 - val_loss: 0.2147 - val_iou_coef: 0.6305\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.21526 to 0.21468, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 22/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2061 - iou_coef: 0.6206 - val_loss: 0.2106 - val_iou_coef: 0.6365\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.21468 to 0.21060, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 23/100\n",
            "22068/22068 [==============================] - 173s 8ms/step - loss: 0.2040 - iou_coef: 0.6234 - val_loss: 0.2107 - val_iou_coef: 0.6418\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.21060\n",
            "Epoch 24/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2023 - iou_coef: 0.6298 - val_loss: 0.2174 - val_iou_coef: 0.6352\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.21060\n",
            "Epoch 25/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.2011 - iou_coef: 0.6330 - val_loss: 0.2083 - val_iou_coef: 0.6443\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.21060 to 0.20827, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 26/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1993 - iou_coef: 0.6382 - val_loss: 0.2098 - val_iou_coef: 0.6459\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.20827\n",
            "Epoch 27/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1987 - iou_coef: 0.6386 - val_loss: 0.2070 - val_iou_coef: 0.6528\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.20827 to 0.20705, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 28/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1973 - iou_coef: 0.6413 - val_loss: 0.2028 - val_iou_coef: 0.6619\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.20705 to 0.20279, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 29/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1961 - iou_coef: 0.6458 - val_loss: 0.2049 - val_iou_coef: 0.6576\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.20279\n",
            "Epoch 30/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1951 - iou_coef: 0.6467 - val_loss: 0.2057 - val_iou_coef: 0.6589\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.20279\n",
            "Epoch 31/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1942 - iou_coef: 0.6495 - val_loss: 0.2009 - val_iou_coef: 0.6596\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.20279 to 0.20090, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 32/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1927 - iou_coef: 0.6537 - val_loss: 0.2004 - val_iou_coef: 0.6653\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.20090 to 0.20041, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 33/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1922 - iou_coef: 0.6536 - val_loss: 0.2036 - val_iou_coef: 0.6617\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.20041\n",
            "Epoch 34/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1910 - iou_coef: 0.6555 - val_loss: 0.2008 - val_iou_coef: 0.6644\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.20041\n",
            "Epoch 35/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1910 - iou_coef: 0.6551 - val_loss: 0.2109 - val_iou_coef: 0.6513\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.20041\n",
            "Epoch 36/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1900 - iou_coef: 0.6584 - val_loss: 0.2002 - val_iou_coef: 0.6687\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.20041 to 0.20019, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 37/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1888 - iou_coef: 0.6594 - val_loss: 0.2010 - val_iou_coef: 0.6666\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.20019\n",
            "Epoch 38/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1877 - iou_coef: 0.6629 - val_loss: 0.1981 - val_iou_coef: 0.6724\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.20019 to 0.19811, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 39/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1871 - iou_coef: 0.6632 - val_loss: 0.1966 - val_iou_coef: 0.6742\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.19811 to 0.19656, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 40/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1863 - iou_coef: 0.6659 - val_loss: 0.1963 - val_iou_coef: 0.6743\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.19656 to 0.19627, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 41/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1858 - iou_coef: 0.6664 - val_loss: 0.1944 - val_iou_coef: 0.6766\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.19627 to 0.19438, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 42/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1857 - iou_coef: 0.6668 - val_loss: 0.1961 - val_iou_coef: 0.6738\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.19438\n",
            "Epoch 43/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1845 - iou_coef: 0.6701 - val_loss: 0.1947 - val_iou_coef: 0.6770\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.19438\n",
            "Epoch 44/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1840 - iou_coef: 0.6710 - val_loss: 0.1937 - val_iou_coef: 0.6784\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.19438 to 0.19371, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 45/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1829 - iou_coef: 0.6722 - val_loss: 0.1953 - val_iou_coef: 0.6752\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.19371\n",
            "Epoch 46/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1825 - iou_coef: 0.6726 - val_loss: 0.1937 - val_iou_coef: 0.6808\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.19371 to 0.19367, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 47/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1819 - iou_coef: 0.6736 - val_loss: 0.1939 - val_iou_coef: 0.6803\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.19367\n",
            "Epoch 48/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1813 - iou_coef: 0.6757 - val_loss: 0.1951 - val_iou_coef: 0.6786\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.19367\n",
            "\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 49/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1787 - iou_coef: 0.6794 - val_loss: 0.1919 - val_iou_coef: 0.6841\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.19367 to 0.19193, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 50/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1783 - iou_coef: 0.6803 - val_loss: 0.1916 - val_iou_coef: 0.6838\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.19193 to 0.19156, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 51/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1779 - iou_coef: 0.6810 - val_loss: 0.1908 - val_iou_coef: 0.6847\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.19156 to 0.19077, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 52/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1775 - iou_coef: 0.6823 - val_loss: 0.1911 - val_iou_coef: 0.6834\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.19077\n",
            "Epoch 53/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1775 - iou_coef: 0.6801 - val_loss: 0.1911 - val_iou_coef: 0.6847\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.19077\n",
            "Epoch 54/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1776 - iou_coef: 0.6802 - val_loss: 0.1907 - val_iou_coef: 0.6846\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.19077 to 0.19067, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 55/100\n",
            "22068/22068 [==============================] - 172s 8ms/step - loss: 0.1773 - iou_coef: 0.6817 - val_loss: 0.1902 - val_iou_coef: 0.6859\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.19067 to 0.19020, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 56/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1773 - iou_coef: 0.6810 - val_loss: 0.1905 - val_iou_coef: 0.6851\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.19020\n",
            "Epoch 57/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1772 - iou_coef: 0.6824 - val_loss: 0.1898 - val_iou_coef: 0.6867\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.19020 to 0.18982, saving model to Models/Final_unet_building_weights.h5\n",
            "Epoch 58/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1768 - iou_coef: 0.6824 - val_loss: 0.1904 - val_iou_coef: 0.6848\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.18982\n",
            "Epoch 59/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1768 - iou_coef: 0.6828 - val_loss: 0.1908 - val_iou_coef: 0.6845\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.18982\n",
            "Epoch 60/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1767 - iou_coef: 0.6832 - val_loss: 0.1900 - val_iou_coef: 0.6858\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.18982\n",
            "Epoch 61/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1766 - iou_coef: 0.6831 - val_loss: 0.1900 - val_iou_coef: 0.6854\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.18982\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 62/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1763 - iou_coef: 0.6842 - val_loss: 0.1901 - val_iou_coef: 0.6861\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.18982\n",
            "Epoch 63/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1762 - iou_coef: 0.6836 - val_loss: 0.1899 - val_iou_coef: 0.6860\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.18982\n",
            "Epoch 64/100\n",
            "22068/22068 [==============================] - 171s 8ms/step - loss: 0.1761 - iou_coef: 0.6843 - val_loss: 0.1901 - val_iou_coef: 0.6855\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.18982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-fcc7a37fdfa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"History/Building_History.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZthE65vN7fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"History/Building_History.pickle\", 'wb') as f:\n",
        "    pickle.dump(history, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5Joz_WJcclW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "9af091f4-53c8-4364-8417-0e3a8658939e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['iou_coef'])\n",
        "plt.plot(history.history['val_iou_coef'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npZTDaSJQSimH00SglFIO9/9pXNqFNyknSgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY0xcliCMMcbEZQnCGGNMXP8/0vrg2Rm3l0YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}